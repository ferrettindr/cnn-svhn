\relax 
\newlabel{eq:sigmoid}{{1}{2}}
\newlabel{eq:softmax}{{2}{2}}
\newlabel{eq:cross-entropy}{{3}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A feedforward network where on each neuron there is a label representing the value computed by it and passed to the nodes of the next layer through the arcs connecting them. A neuron assigns a weight $ \omega $ to each incoming arch and performs the shown linear combination. The sigmoid funciton of equation (1\hbox {}) can be used as the activation function $\sigma $. The function computed by the neurons in the output layer could be $softmax$ (2\hbox {}) where $\boldsymbol  {v}_i = \boldsymbol  {\omega }_{y,i}^T\boldsymbol  {n}_k + b_{y,i}$. Here the bias $ b $ is explicited in the computation rather than adding another dimension to the various vectors $ \boldsymbol  {\omega } $, $ \boldsymbol  {n}$, and $ \boldsymbol  {x} $ so that $ \omega _{r,i,0} = b_{r,i} $ for $ r \in \{j,k,y\} $ and $ x_{0} = n_{p,0} = 1 $ for $p \in \{j,k\} $.\relax }}{3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:mlp}{{1}{3}}
\newlabel{eq:sgd}{{4}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces A visual representation of a convolutional neural network used for image classification. The main components are: the convolutional layers producing the feature maps, the pooling layers used to downsample the convolutional layers output, and a standard fully connected feedforward network to handle classification\relax }}{5}}
\newlabel{fig:cnn}{{2}{5}}
\newlabel{fig:svhn1}{{3a}{7}}
\newlabel{sub@fig:svhn1}{{a}{7}}
\newlabel{fig:svhn2}{{3b}{7}}
\newlabel{sub@fig:svhn2}{{b}{7}}
\newlabel{fig:svhn}{{\caption@xref {fig:svhn}{ on input line 162}}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces (a) The original images obtained from Street View. The blue rectangles describe the position of each digit in the images, they are shown for clarity but are not present in the images, their coordinates are stored in a separate file. (b) The images cropped and centered around a single digit. Note the presence of other digits and distracting elements to the sides.\relax }}{7}}
\newlabel{fig:hista}{{4a}{8}}
\newlabel{sub@fig:hista}{{a}{8}}
\newlabel{fig:histb}{{4b}{8}}
\newlabel{sub@fig:histb}{{b}{8}}
\newlabel{fig:histc}{{4c}{8}}
\newlabel{sub@fig:histc}{{c}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Histograms representing the absolute frequency of the labels for the training set (a), validation set (b), and test set (c). The distribution is very similar among the various sets, making it sound to use them for machine learning tasks.\relax }}{8}}
\newlabel{fig:hist}{{4}{8}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces hyperparameters and their values at each phase of the training\relax }}{10}}
\newlabel{tab:def-hyper}{{1}{10}}
\newlabel{fig:valA}{{5a}{11}}
\newlabel{sub@fig:valA}{{a}{11}}
\newlabel{fig:valB}{{5b}{11}}
\newlabel{sub@fig:valB}{{b}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Loss and accuracy on the validation and reduced training set of the final enlarged model after each epoch of training on the reduced training set.\relax }}{11}}
\newlabel{fig:val_graphs}{{5}{11}}
\newlabel{fig:trainA}{{6a}{11}}
\newlabel{sub@fig:trainA}{{a}{11}}
\newlabel{fig:trainB}{{6b}{11}}
\newlabel{sub@fig:trainB}{{b}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Loss and accuracy on the test and training set of the final enlarged model after each epoch of training on the complete training set\relax }}{11}}
\newlabel{fig:train_graphs}{{6}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The confusion matrix given by the predictions of the model on the test set. The row denotes the true label, the column the predicted label, and the value is the percentages of data points with true label given by the row and prediction given by the column.\relax }}{12}}
\newlabel{fig:conf_mat}{{7}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The top forty wrong predictions to which the model assigns the highest confidence. It is clear the presence of some mislabeling of the examples. The images are shown after the conversion from RGB to grayscale.\relax }}{13}}
\newlabel{fig:worst_PRED}{{8}{13}}
